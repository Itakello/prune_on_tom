{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Evaluate LLama-3.1-8b - ToMBench",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/submodules/ToMBench/run_huggingface.py",
            "console": "integratedTerminal",
            "args": [
                "--model_name",
                "meta-llama/Llama-3.1-8B-Instruct",
                "--language",
                "en",
                "--try_times",
                "3",
            ]
        },
        {
            "name": "Get Results Evaluation",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/submodules/ToMBench/get_results.py",
            "console": "integratedTerminal",
            "args": [
                "--input_path",
                "results",
                "--try_times",
                "5"
            ]
        },
        {
            "name": "Test Wanda",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/submodules/wanda/main.py",
            "console": "integratedTerminal",
            "args": [
                "--model",
                "meta-llama/Llama-3.1-8B-Instruct",
                "--prune_method",
                "wanda",
                "--sparsity_ratio",
                "0.5",
                "--sparsity_type",
                "unstructured",
                "--save",
                "out/wanda/unstructured/llama-3.1-8b",
                "--cache_dir",
                "D:\\tmp\\hf_cache\\hub"
            ]
        },
        {
            "name": "Main",
            "type": "python",
            "request": "launch",
            "program": "main.py",
            "console": "integratedTerminal",
            "args": [
                "--models",
                "meta-llama/Llama-3.2-3b-Instruct",
                "meta-llama/Llama-3.1-8b-Instruct",
                "--seed",
                "43",
                "--train_num",
                "64",
                "--test_num",
                "100",
                "--sparsity_ratios",
                "25",
                "50"
            ],
            "justMyCode": false
        },
        {
            "name": "Analyze pruning",
            "type": "python",
            "request": "launch",
            "program": "analyze_pruning.py",
            "console": "integratedTerminal",
            "args": [],
        },
        {
            "name": "Plot results",
            "type": "python",
            "request": "launch",
            "program": "plot_results.py",
            "console": "integratedTerminal",
            "args": [],
        }
    ]
}